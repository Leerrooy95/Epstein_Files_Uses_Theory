# New Analysis Findings — February 8, 2026

**Purpose:** Document the results of the five planned analyses recommended
by the previous Copilot agent.  Each test was designed to stress-test the
reported friction-compliance correlations from different angles.

**Analyst:** GitHub Copilot (Claude, Opus 4.6)  
**Date:** February 8, 2026  
**Datasets:** Local copies in `Datasets/` (originals in `New_Data_2026/` and
`Control_Proof/`)

---

## ⚠️ Transparency Notice

Everything in this document was generated by an AI language model.  The
statistical tests were run on real data from the repository, but the
interpretation is automated.  Verify all findings independently before
citing them.

---

## Executive Summary

Five planned robustness tests were executed against the friction-compliance
correlations.  The results paint a nuanced picture:

| Test | Core Scope (r=0.62) | Full Scope (r=0.53) | Verdict |
|------|---------------------|---------------------|---------|
| Autocorrelation adjustment | Pearson survives (p=0.0004), Spearman does not (p=0.78) | Both survive (Pearson p=0.0001, Spearman p=0.007) | ⚠️ Mixed |
| Normalization (z-score) | Drops to r=0.23 (still p<0.001) | Drops to r=0.29 (still p<0.001) | ⚠️ Weakened |
| Dec 2025 exclusion | Drops to r=0.06 (not significant) | Drops to r=0.09 (not significant) | ❌ Fails |
| Rolling window (26-wk) | Mean r=0.20, 11% of windows >0.3 | Mean r=0.19, 28% of windows >0.3 | ⚠️ Concentrated |
| Event-study (friction→compliance) | No post-friction clustering (p=1.0) | No post-friction clustering (p=1.0) | ❌ Fails |

**Bottom line:** The headline Pearson r ≈ 0.62 is statistically real (survives
both standard and autocorrelation-adjusted permutation tests), but it
describes a **single-month phenomenon centered on December 2025**, not a
persistent time-series relationship.  When that month is removed, the
correlation vanishes.  At the individual event level, compliance events do
not systematically follow friction events.

This does not mean the December 2025 cluster is unimportant — it may be the
most analytically interesting finding in the data.  But it should be reported
as "an extraordinary concentration of both friction and compliance events in
December 2025" rather than "a persistent correlation across the 2020-2026
timeline."

---

## Test 1: Autocorrelation-Adjusted Significance

**Script:** `Statistical_Tests/autocorrelation_adjusted_test.py`

### Why this test matters

Standard permutation tests shuffle individual observations independently,
which destroys the temporal structure of time-series data.  If friction
events tend to cluster across consecutive weeks (lag-1 autocorrelation),
then random shuffles create unrealistically jagged baselines, making it
too easy for the real data to look "significant."

### Results

**Core scope:**
- Durbin-Watson = 1.29 (positive autocorrelation detected; DW < 1.5)
- Friction lag-1 autocorrelation = 0.667 (substantial)
- Compliance lag-1 autocorrelation = 0.591 (substantial)
- Block bootstrap (4-week blocks, 10,000 iterations):
  - Pearson r=0.62: **p = 0.0004** (survives ✓)
  - Spearman ρ=0.02: **p = 0.78** (not significant ✗)

**Full scope:**
- Durbin-Watson = 1.82 (acceptable range)
- Block bootstrap:
  - Pearson r=0.53: **p = 0.0001** (survives ✓)
  - Spearman ρ=0.17: **p = 0.007** (survives ✓)

### Interpretation

The Pearson correlation survives autocorrelation adjustment in both scopes.
However, the Spearman rank correlation — which is resistant to magnitude
outliers — only survives in the full scope (when High_Growth_Companies adds
breadth).  This confirms the earlier finding that the core-scope Pearson r
is driven by magnitude outliers (a few high-activity weeks), not by consistent
rank-order co-movement.

The full scope tells a more encouraging story: the Spearman ρ=0.17 survives
both standard and block-bootstrap testing, suggesting some genuine rank-order
signal when the dataset is broad enough.

---

## Test 2: Normalized Event-Count Correlation

**Script:** `Statistical_Tests/normalized_correlation.py`

### Why this test matters

December 2025 has dramatically more events than any other period.  Pearson r
is sensitive to magnitude — a single week with 50 events in both columns can
dominate the entire correlation number.  Normalization removes this
inter-year magnitude gap while preserving within-year patterns.

### Results

| Method | Core Pearson r | Core Spearman ρ | Full Pearson r | Full Spearman ρ |
|--------|---------------|-----------------|---------------|-----------------|
| Raw (un-normalized) | 0.619 | 0.022 | 0.528 | 0.170 |
| Per-year z-score | 0.230 | 0.015 | 0.285 | 0.072 |
| Per-year proportional | 0.098 | -0.206 | 0.150 | -0.004 |
| Binary (presence/absence) | -0.406 | -0.406 | -0.194 | -0.194 |

### Interpretation

- **Z-score normalization** cuts the Pearson r by roughly 60% (0.62→0.23
  core, 0.53→0.29 full) but both remain statistically significant
  (p < 0.001).  This means there IS some genuine within-year co-movement
  beyond the inter-year magnitude gap, but it's much weaker than the raw
  number suggests.

- **Proportional scaling** produces near-zero correlations in the core scope
  and a small positive correlation in full scope, suggesting that when each
  year contributes equally, the weekly co-movement pattern nearly disappears.

- **Binary analysis** reveals a striking negative correlation (-0.41 core):
  friction and compliance tend to occur in *different* weeks, not the same
  ones.  This makes sense — compliance events (e.g., corporate actions,
  policy shifts) happen year-round, while friction events cluster in certain
  periods.  Only 45 of 213 weeks have any friction events at all, but 204 of
  213 have compliance events.  The raw positive Pearson r is driven by the
  few weeks where BOTH types spike simultaneously (December 2025).

---

## Test 3: Cross-Validation — December 2025 Exclusion

**Script:** `Statistical_Tests/cross_validation_dec2025.py`

### Why this test matters

If removing a single month destroys the correlation, the headline number
describes one anomalous period, not a persistent relationship.

### Results

| Window | Core r | Core p | Full r | Full p |
|--------|--------|--------|--------|--------|
| Full dataset | 0.619 | <0.0001 | 0.528 | <0.0001 |
| Dec 2025 excluded | 0.060 | 0.390 | 0.093 | 0.121 |
| Nov-Dec 2025 excluded | 0.098 | 0.162 | 0.091 | 0.129 |
| All 2025 excluded | 0.107 | 0.175 | 0.221 | 0.001 |
| Only 2025 | 0.738 | <0.0001 | 0.780 | <0.0001 |
| Only pre-2025 | 0.107 | 0.175 | 0.221 | 0.001 |

### Interpretation

- **Removing December 2025 causes a 90% drop** in the core scope (0.62→0.06)
  and an 82% drop in the full scope (0.53→0.09).  Neither survives at p<0.05.

- **Within 2025 alone**, the correlation is even stronger (r=0.74–0.78),
  confirming that 2025 — especially December — drives the entire result.

- **Pre-2025 data** shows no significant correlation in the core scope.  The
  full scope shows a weak but significant r=0.22 (p=0.001), again suggesting
  that the broader dataset (with High_Growth_Companies) has more genuine
  signal than the curated core.

- **This is the most important finding:** the reported r ≈ 0.62 is not a
  broad time-series pattern.  It is a December 2025 phenomenon.

---

## Test 4: Rolling-Window Correlation

**Script:** `Statistical_Tests/rolling_window_correlation.py`

### Why this test matters

A single correlation number hides the time structure.  Rolling windows reveal
where in the timeline the relationship actually exists.

### Results (26-week window, core scope)

- Mean rolling r = 0.196 (much lower than full-sample r = 0.619)
- Median rolling r = 0.172
- Only 11% of windows have r > 0.3
- 0% of windows have r < -0.3
- Top windows all include late 2025 (r=0.79 for Jun-Dec 2025)

### Regime analysis (52-week window, core scope)

- Early third (2020-2022): mean r = 0.089
- Middle third (2022-2024): mean r = 0.173
- Late third (2024-2026): mean r = 0.179

The correlation does increase over time, but the early-period values are
near zero, confirming that the relationship is concentrated in recent data.

### Interpretation

The rolling analysis confirms the cross-validation finding: the correlation
is not stable across the timeline.  Most windows show a modest positive
correlation (r ≈ 0.15-0.20), but the dramatic values (r > 0.5) only appear
when the window includes December 2025.  The full-sample r = 0.62 is an
average dominated by one tail.

However, the consistently positive (though small) rolling r across most
periods is noteworthy.  It suggests that friction and compliance events do
tend to co-occur weakly across the entire timeline — just not at the dramatic
level the headline number implies.

---

## Test 5: Event-Study Framework

**Script:** `Statistical_Tests/event_study_framework.py`

### Why this test matters

The most direct test of the "friction triggers compliance" hypothesis.
Instead of aggregate correlation, this checks whether individual compliance
events cluster in a defined window AFTER each friction event.

### Results (core scope)

**Pre vs Post comparison:**

| Window | Post-friction mean | Pre-friction mean | Ratio | Mann-Whitney p |
|--------|-------------------|-------------------|-------|----------------|
| 1 day | 1.75 | 1.43 | 1.22x | 0.065 |
| 7 days | 5.81 | 8.31 | 0.70x | 0.999 |
| 14 days | 9.08 | 16.33 | 0.56x | 1.000 |
| 28 days | 12.02 | 24.41 | 0.49x | 1.000 |

**Random baseline comparison:**

| Window | Actual mean | Random mean | Ratio |
|--------|------------|-------------|-------|
| 1 day | 1.75 | 0.18 | 9.8x |
| 7 days | 5.81 | 1.30 | 4.5x |
| 14 days | 9.08 | 2.60 | 3.5x |
| 28 days | 12.02 | 5.34 | 2.3x |

### Interpretation

There are TWO competing signals in the event-study results:

1. **Post-friction windows have FEWER compliance events than pre-friction
   windows** (ratio <1.0 at 7+ days).  This is the opposite of the
   "friction triggers compliance" hypothesis.  The reason: friction events
   cluster in December 2025, and compliance events are concentrated in the
   SAME cluster — so the pre-friction window (which looks backward into the
   cluster) captures more events than the post-friction window (which looks
   forward past the cluster's end).

2. **Friction event dates DO have more compliance activity than random dates**
   (4-10x more).  But this reflects COLOCATION — friction and compliance
   events cluster in the same time periods — not a causal mechanism where
   friction *triggers* compliance.

The 1-day window shows a marginal post>pre effect (p=0.065), suggesting
that friction and compliance events may co-occur on the same day or within
24 hours.  This is consistent with simultaneous reactions to the same
underlying trigger (e.g., a policy announcement generates both friction
media coverage and compliance corporate actions on the same day) rather
than a sequential friction→compliance mechanism.

---

## Overall Assessment

### What the data shows

1. **December 2025 is genuinely extraordinary.**  Both friction and compliance
   events concentrate dramatically in this period.  The r=0.74 within 2025
   alone is the strongest finding in the dataset.

2. **The aggregate r ≈ 0.62 is technically real** (survives permutation and
   autocorrelation-adjusted testing) but **misleading as a headline number**
   because it describes one month, not five years.

3. **There IS a weak, persistent positive signal** (z-score normalized r ≈
   0.23-0.29, rolling mean r ≈ 0.17-0.20) that spans the broader timeline.
   This is much weaker than the headline number but is statistically
   significant.

4. **Friction does not appear to "trigger" compliance** at the individual
   event level.  The co-occurrence is better explained by shared temporal
   clustering (both types of events respond to the same underlying triggers)
   than by a sequential mechanism.

### Recommendations

1. **Report the normalized r alongside the raw r.**  "r = 0.62 raw, r = 0.23
   after per-year normalization" is more honest than r = 0.62 alone.

2. **Report the Dec-excluded r.**  "r = 0.06 when December 2025 is removed"
   is essential context for any claim about a persistent time-series pattern.

3. **Focus on December 2025 as a case study** rather than as evidence of a
   broad pattern.  The event-study framework could be adapted to analyze what
   specifically happened in that month and why both friction and compliance
   events concentrated simultaneously.

4. **Backfill earlier years** (per `backfill_guide.md`) to create a dataset
   where no single month can dominate the correlation.  This would allow a
   fairer test of the persistent-signal hypothesis.

5. **Use Spearman ρ as the primary metric** rather than Pearson r.  The
   full-scope Spearman ρ = 0.17 (significant even after block-bootstrap
   adjustment, p = 0.007) is a more honest measure of the underlying signal
   strength than Pearson r = 0.53.

6. **Investigate the "same-day co-occurrence" pattern.**  The event-study's
   1-day window shows marginal significance (p = 0.065), suggesting that
   friction and compliance events may share common triggers rather than
   operating in sequence.

---

## Limitations of This Analysis

| Limitation | Impact | Mitigation |
|-----------|--------|------------|
| Event classification is rule-based | Categories may be misassigned | Manual review of category assignments |
| Datasets have uneven year coverage | 2025-heavy datasets inflate 2025 cluster | Z-score normalization partially addresses this |
| Block bootstrap block size is heuristic | May not fully capture temporal structure | Tried multiple block sizes; results stable |
| Event-study counts overlapping windows | Friction events near each other share compliance events | Non-overlapping event selection would reduce sample size |
| No causal identification | All tests measure association, not causation | Explicitly state "association" not "causation" |

---

*Compiled by GitHub Copilot (Claude, Opus 4.6), February 8, 2026*
